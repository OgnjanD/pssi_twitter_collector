{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lxml import html\n",
    "import urllib.request\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import requests\n",
    "import lxml.html\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import pymysql\n",
    "\n",
    "count = range(1,11)\n",
    "\n",
    "host = os.environ.get('sqlHost')\n",
    "user = os.environ.get('sqlUser')\n",
    "password = os.environ.get('sqlPassword')\n",
    "db = os.environ.get('sqlDatabase')\n",
    "\n",
    "connection = pymysql.connect(\n",
    "    host = sqlHost,\n",
    "    user = sqlUser,\n",
    "    password = sqlPassword,\n",
    "    db = sqlDatabase,\n",
    "    cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "\n",
    "def create_tables(sql_statement):\n",
    "    c = connection.cursor()\n",
    "    c.execute(sql_statement)\n",
    "    return connection.commit()\n",
    "\n",
    "create_tables(\"CREATE TABLE IF NOT EXISTS top_discussed_tweets (tweet_id INT AUTO_INCREMENT PRIMARY KEY,tweet_url VARCHAR(255) NOT NULL);\")\n",
    "create_tables(\"CREATE TABLE IF NOT EXISTS top_t_index (rank INT, handle VARCHAR(255) NOT NULL, t_index INT, timestamp DATETIME);\")\n",
    "create_tables(\"CREATE TABLE IF NOT EXISTS top_f_index (rank INT, handle VARCHAR(255) NOT NULL, no_followers INT, timestamp DATETIME);\")\n",
    "create_tables(\"CREATE TABLE IF NOT EXISTS top_daily_tweets (tweet_id INT AUTO_INCREMENT PRIMARY KEY,tweet_url VARCHAR(255) NOT NULL);\")\n",
    "create_tables(\"CREATE TABLE IF NOT EXISTS top_reach (rank INT, handle VARCHAR(255) NOT NULL, reach INT, timestamp DATETIME);\") \n",
    "\n",
    "def update_tables(table, sqlstatement):\n",
    "    for l in table:\n",
    "        create_tables(sqlstatement.format(l[0], l[2], l[3], datetime.datetime.now()))\n",
    "\n",
    "def update_urls(table, sqlstatement):\n",
    "    for l in table:\n",
    "        create_tables(sqlstatement.format(l))\n",
    "\n",
    "def tweet_collector(url):\n",
    "    top_24h = []\n",
    "    for c in count:\n",
    "        try:\n",
    "            temp_url = lxml.html.fromstring(requests.get(url + str(c)).content)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"failed at\", c, datetime.datetime.now())\n",
    "        top_24h.append(temp_url)\n",
    "\n",
    "    tweet_links = [x.xpath('//a/@href') for x in top_24h]\n",
    "    tweet_links = list(itertools.chain(*tweet_links))\n",
    "    tweet_links = [str(x) for x in tweet_links if re.match(r\"https://twitter.com/.*/status/\", x)]\n",
    "    return tweet_links\n",
    "\n",
    "def get_table(url):\n",
    "    index_table = []\n",
    "    for c in count:\n",
    "        try:\n",
    "            source = url + str(c)\n",
    "            tables = pd.read_html(source) # Returns list of all tables on page\n",
    "            tables = tables[0]\n",
    "            tables = tables[1:].values.tolist() \n",
    "        except:\n",
    "            pass\n",
    "        index_table.extend(tables)\n",
    "    return index_table\n",
    "\n",
    "#relevant urls\n",
    "top24htweets = 'https://time.mk/twitter/2/'\n",
    "topdiscuss = 'https://time.mk/twitter/topdiscuss/'\n",
    "topindex = 'https://time.mk/twitter/toptindex/'\n",
    "topfollowers = 'https://time.mk/twitter/topfoll/'\n",
    "topreach = 'https://time.mk/twitter/topreach/'\n",
    "\n",
    "#call functions \n",
    "daily_tweets = tweet_collector(top24htweets)\n",
    "daily_discuss = tweet_collector(topdiscuss)\n",
    "daily_top_index = get_table(topindex)\n",
    "daily_top_followers = get_table(topfollowers)\n",
    "daily_top_reach = get_table(topreach)\n",
    "\n",
    "update_urls(daily_tweets,\"INSERT INTO top_daily_tweets(tweet_url) VALUES('{}')\")\n",
    "logging.info(\"updated daily tweets\")\n",
    "update_urls(daily_discuss,\"INSERT INTO top_discussed_tweets (tweet_url) VALUES('{}')\")\n",
    "logging.info(\"top discuss\")\n",
    "update_tables(daily_top_index, \"INSERT INTO top_t_index (rank, handle, t_index, timestamp) VALUES ('{}', '{}', '{}', '{}')\")\n",
    "logging.info(\"updated top_t_index\")\n",
    "update_tables(daily_top_followers, \"INSERT INTO top_f_index (rank, handle, no_followers, timestamp) VALUES ('{}', '{}', '{}', '{}')\")\n",
    "logging.info(\"updated top_t_index\")\n",
    "update_tables(daily_top_reach, \"INSERT INTO top_reach (rank, handle, reach, timestamp) VALUES('{}', '{}','{}', '{}')\")\n",
    "logging.info(\"updated daily_top_reach\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
